{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN: Generative Adversarial networks \n",
    "\n",
    "GANs are able to learn how to reproduce synthetic data that looks real. For instance,\n",
    "computers can learn how to paint and create realistic images.\n",
    "\n",
    "The key intuition of GAN can be easily considered as analogous to art forgery, which is the process\n",
    "of creating works of art that are falsely credited to other, usually more\n",
    "famous, artists. GANs train two neural nets simultaneously:\n",
    "- The generator G(Z) makes the forgery, and \n",
    "- The discriminator D(Y) can judge how realistic the reproductions based on its observations of authentic pieces of arts and copies are.\n",
    "\n",
    "D(Y) takes an\n",
    "input, Y, (for instance, an image) and expresses a vote to judge how real the input is--in general, a\n",
    "value close to zero denotes real and a value close to one denotes forgery. G(Z) takes an input from a\n",
    "random noise, Z, and trains itself to fool D into thinking that whatever G(Z) produces is real. So, the\n",
    "goal of training the discriminator D(Y) is to maximize D(Y) for every image from the true data\n",
    "distribution, and to minimize D(Y) for every image not from the true data distribution. So, G and D\n",
    "play an opposite game; hence the name adversarial training.\n",
    "\n",
    "The generative model learns how to forge more successfully, and the discriminative\n",
    "model learns how to recognize forgery more successfully.\n",
    "\n",
    "The discriminator network (usually a\n",
    "standard convolutional neural network) tries to classify whether an input image is real or generated.\n",
    "The important new idea is to backpropagate through both the discriminator and the generator to adjust\n",
    "the generator's parameters in such a way that the generator can learn how to fool the the discriminator\n",
    "for an increasing number of situations. At the end, the generator will learn how to produce forged\n",
    "images that are indistinguishable from real ones.\n",
    "\n",
    "**Paper:** Unsupervised Representation Learning with\n",
    "Deep Convolutional Generative Adversarial Networks, by A. Radford, L. Metz, and S. Chintala, 2015. -> https://arxiv.org/abs/1511.06434\n",
    "\n",
    "### Deep Convolutional GAN\n",
    "<img src=\"DCGAN.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN applied to MNIST to forge the hand write numbers\n",
    "https://github.com/jacobgil/keras-dcgan\n",
    "\n",
    "https://github.com/bstriner/keras-adversarial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the code you need\n",
    "- 1: Create a nre file named as dcgan.py \n",
    "- 2: Copy the code lines to this new file \n",
    "\n",
    "\n",
    "\n",
    "**Usage Training:**\n",
    "\n",
    "        python dcgan.py --mode train --batch_size <batch_size>\n",
    "\n",
    "        python dcgan.py --mode train --path ~/images --batch_size 128\n",
    "\n",
    "**Image generation:**\n",
    "\n",
    "        python dcgan.py --mode generate --batch_size <batch_size>\n",
    "\n",
    "        python dcgan.py --mode generate --batch_size <batch_size> --nice : top 5% images according to discriminator\n",
    "\n",
    "        python dcgan.py --mode generate --batch_size 128\n",
    "      \n",
    "**Note:** Once I only have insterest to run only the training: \n",
    "         \n",
    "         python dcgan.py --mode train\n",
    "         \n",
    "**Note that** Training GANs could be\n",
    "very difficult because it is necessary to find the equilibrium between two players. If you are\n",
    "interested in this topic, I'd advise you to have a look at a series of tricks collected by practitioners (htt\n",
    "ps://github.com/soumith/ganhacks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist #dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "     \n",
    "    \"\"\"The first dense layer takes a vector of 100 dimensions as input and it\n",
    "    produces 1,024 dimensions with the activation function tanh as the output.\n",
    "    We assume that the input is sampled from a uniform distribution in [-1, 1].\"\"\"\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))   \n",
    "    model.add(Activation('tanh'))                         \n",
    "    \n",
    "    \"\"\" The next dense layer produces data of 128 x 7 x 7 in the output using batch\n",
    "    normalization (for more information refer to Batch Normalization: Accelerating Deep Network Training\n",
    "    by Reducing Internal Covariate Shift, by S. Ioffe and C. Szegedy, arXiv: 1502.03167, 2014), \n",
    "    a technique that can help stabilize learning by normalizing the input to each unit to zero mean\n",
    "    and unit variance. Batch normalization has been empirically proven to accelerate the training in\n",
    "    many situations, reduce the problems of poor initialization, and more generally produce more accurate results.\"\"\"\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    \"\"\"The Reshape() module produces data of 128 x 7 x 7 \n",
    "    (128 channels, 7 width, and 7 height), dim_ordering to tf, and a UpSampling() module that produces a\n",
    "    repetition of each one into a 2 x 2 square.\"\"\"\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    \n",
    "    \"\"\"The convolutional layer producing 64 filters on 5 x 5 convolutional kernels with the activation tanh,\n",
    "    followed by a new UpSampling() \"\"\"\n",
    "    model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    \n",
    "    \"\"\"A final convolution with one filter, and on 5 x 5 convolutional kernels with the activation tanh.\"\"\"\n",
    "    model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5),padding='same',input_shape=(28, 28, 1)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (5, 5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(g) \n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    # The code takes a standard MNIST image with the shape (1, 28, 28)\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()                        # load data\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None]\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    # X_train = X_train.reshape((X_train.shape, 1) + X_train.shape[1:])\n",
    "    \"\"\"\n",
    "    Applies a convolution with 64 filters of size 5 x 5 with tanh as the activation function. \n",
    "    This is followed by a max-pooling operation of size 2 x 2 and by a further convolution \n",
    "    max-pooling operation. The last two stages are dense, with the final one being the prediction\n",
    "    for forgery, which consists of only one neuron with a sigmoid activation function.\n",
    "    \"\"\"\n",
    "    d = discriminator_model()                                                      # discriminator model\n",
    "    g = generator_model()                                                          # generator model\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    For a chosen number of epochs, the generator and discriminator are in turn\n",
    "    trained by using binary_crossentropy as loss function.\n",
    "    \"\"\"\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    for epoch in range(100):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            # We assume that the input is sampled from a uniform distribution in [-1, 1]\n",
    "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100)) \n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = g.predict(noise, verbose=0)\n",
    "            if index % 20 == 0:\n",
    "                image = combine_images(generated_images)                           # combine images\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\n",
    "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "            d.trainable = False\n",
    "            g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "            \"\"\"\n",
    "            At each epoch, the generator makes a number of\n",
    "            predictions (for example, it creates forged MNIST images) and the discriminator tries to learn after\n",
    "            mixing the prediction with real MNIST images.\n",
    "            \"\"\"\n",
    "            d.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                g.save_weights('generator', True)\n",
    "                d.save_weights('discriminator', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice=False):\n",
    "    g = generator_model()\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"generated_image.png\")\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", type=str)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
    "    parser.set_defaults(nice=False)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    if args.mode == \"train\":\n",
    "        train(BATCH_SIZE=args.batch_size)\n",
    "    elif args.mode == \"generate\":\n",
    "generate(BATCH_SIZE=args.batch_size, nice=args.nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10\n",
    "classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets\n",
    "provides 10,000 images. This image taken from the CIFAR repository (https://www.cs.toronto.edu/~kriz/cifar.ht\n",
    "ml) describes a few random examples from the 10 classes:\n",
    "<img src=\"cifar.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to recognize previously unseen images and assign them to one of the 10 classes. Let us\n",
    "define a suitable deep net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ctw00071\\AppData\\Local\\Continuum\\miniconda3\\envs\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop() #Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 85s 0us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',                        # 32 convolutional filters, each of which\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))   # with a 3 x 3 size\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))                           # max-pooling operation with pool size 2 x 2\n",
    "model.add(Dropout(0.25))                                            # dropout at 25% \n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))                                               # dense network with 512 units\n",
    "model.add(Activation('relu'))                                       # ReLU activation\n",
    "model.add(Dropout(0.5))                                             # dropout at 50%  \n",
    "\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))                                    # softmax layer with 10 classes as output\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "- **Training**: it is used to build our models,\n",
    "- **Validation**: it is used to select the best performing approach\n",
    "- **Test**: it is to check the performance of our best models on fresh unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 36s 890us/step - loss: 2.3029 - acc: 0.0993 - val_loss: 2.3026 - val_acc: 0.1016\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 37s 914us/step - loss: 2.3028 - acc: 0.0947 - val_loss: 2.3028 - val_acc: 0.0952\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 35s 866us/step - loss: 2.3027 - acc: 0.0995 - val_loss: 2.3028 - val_acc: 0.0952\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 35s 867us/step - loss: 2.3027 - acc: 0.1004 - val_loss: 2.3027 - val_acc: 0.0977\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 35s 870us/step - loss: 2.3027 - acc: 0.0974 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 35s 866us/step - loss: 2.3027 - acc: 0.0992 - val_loss: 2.3028 - val_acc: 0.0952\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 36s 892us/step - loss: 2.3027 - acc: 0.1007 - val_loss: 2.3028 - val_acc: 0.0952\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 40s 1ms/step - loss: 2.3027 - acc: 0.0979 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 41s 1ms/step - loss: 2.3027 - acc: 0.0986 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 40s 1ms/step - loss: 2.3027 - acc: 0.0980 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 41s 1ms/step - loss: 2.3027 - acc: 0.0982 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 38s 949us/step - loss: 2.3027 - acc: 0.1001 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 37s 936us/step - loss: 2.3027 - acc: 0.0967 - val_loss: 2.3026 - val_acc: 0.1025\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 36s 897us/step - loss: 2.3027 - acc: 0.0987 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 43s 1ms/step - loss: 2.3027 - acc: 0.1002 - val_loss: 2.3028 - val_acc: 0.0952\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 40s 1000us/step - loss: 2.3027 - acc: 0.0987 - val_loss: 2.3028 - val_acc: 0.0952\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 39s 968us/step - loss: 2.3027 - acc: 0.1003 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 39s 966us/step - loss: 2.3027 - acc: 0.0994 - val_loss: 2.3028 - val_acc: 0.0952\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 42s 1ms/step - loss: 2.3027 - acc: 0.0984 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 40s 988us/step - loss: 2.3027 - acc: 0.1001 - val_loss: 2.3028 - val_acc: 0.0952\n",
      "10000/10000 [==============================] - 2s 210us/step\n",
      "Test score: 2.302638740539551\n",
      "Test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=OPTIM,\n",
    "              metrics=['accuracy'])\n",
    "#Train\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NB_EPOCH, \n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "          verbose=VERBOSE)\n",
    "#Test\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                       batch_size=BATCH_SIZE, \n",
    "                       verbose=VERBOSE)\n",
    "#Print Result\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the architecture of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

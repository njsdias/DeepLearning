{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.ones(2,2), requires_grad =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3316.0713, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a, b = 12, 23\n",
    "x1 = Variable(torch.randn(a,b),\n",
    "             requires_grad = True)\n",
    "x2 = Variable(torch.randn(a,b),\n",
    "             requires_grad = True)\n",
    "x3 = Variable(torch.randn(a,b),\n",
    "             requires_grad = True)\n",
    "\n",
    "C = x1 * x2\n",
    "d = a + x3\n",
    "e = torch.sum(d)\n",
    "e.backward()\n",
    "print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.9167, dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the descriptive statistics: mean\n",
    "torch.mean(torch.tensor([10,10,13,10,34,45,65,67,87,89,87,34], dtype = torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7580,  0.9145, -0.4105, -0.5565,  0.3587],\n",
       "        [-1.1314,  0.1342, -0.7378, -0.7275,  1.1701],\n",
       "        [ 0.8765,  0.3984,  0.2653, -0.6982,  0.3870],\n",
       "        [-0.5492,  0.0208, -1.5774,  0.0532,  0.3439]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean across rows and across columns\n",
    "d = torch.randn(4,5)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8905,  0.3670, -0.6151, -0.4822,  0.5649])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(d,dim=0) # mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4904, -0.2585,  0.2458, -0.3417])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(d,dim=1) # mean of each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median, mode, and standard deviation computation can be written in\n",
    "the same way:\n",
    "\n",
    "    torch.median\n",
    "    torch.mode\n",
    "    torch.std\n",
    "    torch.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-2.7580, -0.5565, -0.4105,  0.3587,  0.9145],\n",
       "        [-1.1314, -0.7378, -0.7275,  0.1342,  1.1701],\n",
       "        [-0.6982,  0.2653,  0.3870,  0.3984,  0.8765],\n",
       "        [-1.5774, -0.5492,  0.0208,  0.0532,  0.3439]]),\n",
       "indices=tensor([[0, 3, 2, 4, 1],\n",
       "        [0, 2, 3, 1, 4],\n",
       "        [3, 2, 4, 1, 0],\n",
       "        [2, 0, 1, 3, 4]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting a tensor\n",
    "torch.sort(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-2.7580,  0.0208, -1.5774, -0.7275,  0.3439],\n",
       "        [-1.1314,  0.1342, -0.7378, -0.6982,  0.3587],\n",
       "        [-0.5492,  0.3984, -0.4105, -0.5565,  0.3870],\n",
       "        [ 0.8765,  0.9145,  0.2653,  0.0532,  1.1701]]),\n",
       "indices=tensor([[0, 3, 3, 1, 3],\n",
       "        [1, 1, 1, 2, 0],\n",
       "        [3, 2, 0, 0, 2],\n",
       "        [2, 0, 2, 3, 1]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(d,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-2.7580,  0.0208, -1.5774, -0.7275,  0.3439],\n",
       "        [-1.1314,  0.1342, -0.7378, -0.6982,  0.3587],\n",
       "        [-0.5492,  0.3984, -0.4105, -0.5565,  0.3870],\n",
       "        [ 0.8765,  0.9145,  0.2653,  0.0532,  1.1701]]),\n",
       "indices=tensor([[0, 3, 3, 1, 3],\n",
       "        [1, 1, 1, 2, 0],\n",
       "        [3, 2, 0, 0, 2],\n",
       "        [2, 0, 2, 3, 1]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(d,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[ 0.8765,  0.9145,  0.2653,  0.0532,  1.1701],\n",
       "        [-0.5492,  0.3984, -0.4105, -0.5565,  0.3870],\n",
       "        [-1.1314,  0.1342, -0.7378, -0.6982,  0.3587],\n",
       "        [-2.7580,  0.0208, -1.5774, -0.7275,  0.3439]]),\n",
       "indices=tensor([[2, 0, 2, 3, 1],\n",
       "        [3, 2, 0, 0, 2],\n",
       "        [1, 1, 1, 2, 0],\n",
       "        [0, 3, 3, 1, 3]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(d,dim=0,descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[ 0.9145,  0.3587, -0.4105, -0.5565, -2.7580],\n",
       "        [ 1.1701,  0.1342, -0.7275, -0.7378, -1.1314],\n",
       "        [ 0.8765,  0.3984,  0.3870,  0.2653, -0.6982],\n",
       "        [ 0.3439,  0.0532,  0.0208, -0.5492, -1.5774]]),\n",
       "indices=tensor([[1, 4, 2, 3, 0],\n",
       "        [4, 1, 3, 2, 0],\n",
       "        [0, 1, 4, 2, 3],\n",
       "        [4, 3, 1, 0, 2]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(d,dim=1,descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Computation\n",
    "We are going to consider a sample datase0074, where two variables (x and y)\n",
    "are present. With the initial weight given, can we computationally get the\n",
    "gradients after each iteration?\n",
    "\n",
    "To compute the gradient of the two data\n",
    "lists requires computation of a loss function, a forward pass, and running\n",
    "the stuff in a loop.\n",
    "\n",
    "The forward function computes the matrix multiplication of the weight\n",
    "tensor with the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using forward pass\n",
    "def forward(x):\n",
    "    return x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "x_data = [11.0, 22.0, 33.0]\n",
    "y_data = [21.0, 14.0, 64.0]\n",
    "\n",
    "w = Variable(torch.Tensor([1.0]), requires_grad = True)   #Any random value\n",
    "\n",
    "#Before training\n",
    "print(\"predict (before training)\",  4, forward(4).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Loss Function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y ) * (y_pred * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  11.0 21.0 tensor(231.)\n",
      "\tgrad:  22.0 14.0 tensor(-22065.1191)\n",
      "\tgrad:  33.0 64.0 tensor(30439240.)\n",
      "progress: 0 tensor(3.3235e+09)\n",
      "\tgrad:  11.0 21.0 tensor(-1.5458e+09)\n",
      "\tgrad:  22.0 14.0 tensor(2.0537e+11)\n",
      "\tgrad:  33.0 64.0 tensor(-2.8415e+14)\n",
      "progress: 1 tensor(2.8962e+23)\n",
      "\tgrad:  11.0 21.0 tensor(1.4430e+16)\n",
      "\tgrad:  22.0 14.0 tensor(-1.9171e+18)\n",
      "\tgrad:  33.0 64.0 tensor(2.6526e+21)\n",
      "progress: 2 tensor(2.5239e+37)\n",
      "\tgrad:  11.0 21.0 tensor(-1.3471e+23)\n",
      "\tgrad:  22.0 14.0 tensor(1.7896e+25)\n",
      "\tgrad:  33.0 64.0 tensor(-2.4762e+28)\n",
      "progress: 3 tensor(inf)\n",
      "\tgrad:  11.0 21.0 tensor(1.2575e+30)\n",
      "\tgrad:  22.0 14.0 tensor(-1.6706e+32)\n",
      "\tgrad:  33.0 64.0 tensor(2.3115e+35)\n",
      "progress: 4 tensor(inf)\n",
      "\tgrad:  11.0 21.0 tensor(-1.1739e+37)\n",
      "\tgrad:  22.0 14.0 tensor(inf)\n",
      "\tgrad:  33.0 64.0 tensor(-inf)\n",
      "progress: 5 tensor(inf)\n",
      "\tgrad:  11.0 21.0 tensor(nan)\n",
      "\tgrad:  22.0 14.0 tensor(nan)\n",
      "\tgrad:  33.0 64.0 tensor(nan)\n",
      "progress: 6 tensor(nan)\n",
      "\tgrad:  11.0 21.0 tensor(nan)\n",
      "\tgrad:  22.0 14.0 tensor(nan)\n",
      "\tgrad:  33.0 64.0 tensor(nan)\n",
      "progress: 7 tensor(nan)\n",
      "\tgrad:  11.0 21.0 tensor(nan)\n",
      "\tgrad:  22.0 14.0 tensor(nan)\n",
      "\tgrad:  33.0 64.0 tensor(nan)\n",
      "progress: 8 tensor(nan)\n",
      "\tgrad:  11.0 21.0 tensor(nan)\n",
      "\tgrad:  22.0 14.0 tensor(nan)\n",
      "\tgrad:  33.0 64.0 tensor(nan)\n",
      "progress: 9 tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "for epoch in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "        \n",
    "        #Manually set the gradients to zero after updating weights\n",
    "        w.grad.data.zero_()\n",
    "    print(\"progress:\", epoch, l.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (after training) 4 tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "# After training\n",
    "print(\"predict (after training)\",  4, forward(4).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following program shows how to compute the gradients from a\n",
    "loss function using the variable method on the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of w1 w.r.t. to Loss: -455.0\n",
      "Gradient of w2 w.r.t. to Loss: -365.0\n",
      "Gradient of w3 w.r.t. to Loss: -60.0\n",
      "Gradient of w4 w.r.t. to Loss: -265.0\n"
     ]
    }
   ],
   "source": [
    "a = Variable(FloatTensor([5]))\n",
    "\n",
    "weights = [Variable(FloatTensor([i]), requires_grad = True) for i in (12, 53, 91, 73)]\n",
    "\n",
    "w1, w2, w3, w4 = weights\n",
    "\n",
    "b = w1 * a  # Multiply 5.0 x 12. = 60.0\n",
    "c = w2 * a\n",
    "d = w3 * b + w4 * c\n",
    "Loss = (10 - d)\n",
    "\n",
    "Loss.backward()\n",
    "\n",
    "for index , weight in enumerate(weights, start=1):\n",
    "    gradient, *_ =weight.grad.data\n",
    "    print(f\"Gradient of w{index} w.r.t. to Loss: {gradient}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "How do we compute or perform operations based on variables such as matrix multiplication?\n",
    "\n",
    "**Tensors** are wrapped within the variable, which has three properties: **grad, volatile, and gradient**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Multiplications\n",
    "x = Variable(torch.Tensor(4,4).uniform_(-4, 5))\n",
    "y = Variable(torch.Tensor(4, 4).uniform_(-3,2))\n",
    "\n",
    "z = torch.mm(x,y)   #multiplication between tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3531, -2.6178,  4.3037,  4.5532],\n",
       "        [ 1.3402,  4.0281,  1.5340,  3.4727],\n",
       "        [ 0.8130, -2.1690, -1.1658, -0.7814],\n",
       "        [-3.5085,  1.9880, -2.6271,  0.3081]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0429, -0.5066,  0.3660, -1.4421],\n",
       "        [-0.3115,  0.4284, -0.8424, -1.2246],\n",
       "        [-2.3190, -0.4118, -1.7182, -2.2663],\n",
       "        [-0.2495, -2.3306, -1.4017,  1.9815]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requires Gradient: False\n",
      "Volatile: False\n",
      "Gradient: None\n",
      "tensor([[-10.1566, -11.8070, -12.7989,   7.3102],\n",
      "        [ -5.7358,  -7.6786, -10.4061,  -3.4609],\n",
      "        [  3.5390,   0.9602,   5.2231,   2.5775],\n",
      "        [  5.5468,   2.9928,   1.1233,   9.1895]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ctw00071\\AppData\\Local\\Continuum\\miniconda3\\envs\\pytorch_tutorial_123\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: volatile was removed (Variable.volatile is always False)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\"Requires Gradient: %s\" %(z.requires_grad))\n",
    "print(\"Volatile: %s\" % (z.volatile))\n",
    "print(\"Gradient: %s\" % (z.grad))\n",
    "print(z.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "A 1D tensor is a vector, and a 2D tensor is a matrix.\n",
    "\n",
    "When performing algebraic computations in PyTorch, the dimension of a matrix and a vector or scalar should be compatible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2627, 0.6943, 0.3262, 0.0570],\n",
       "        [0.3390, 0.5194, 0.6633, 0.0852],\n",
       "        [0.1061, 0.5970, 0.2915, 0.3432],\n",
       "        [0.5721, 0.9952, 0.1315, 0.4609]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.FloatTensor(4,4).uniform_(0,1)\n",
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4062, 0.3610, 0.3187, 0.1473],\n",
       "        [0.4093, 0.7949, 0.2525, 0.5676],\n",
       "        [0.4616, 0.8362, 0.8348, 0.9533],\n",
       "        [0.0241, 0.6182, 0.3517, 0.8078],\n",
       "        [0.2006, 0.8054, 0.7338, 0.5032]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 = torch.FloatTensor(5,4).uniform_(0,1)\n",
    "mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0142, 0.5554, 0.2253, 0.4906])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 = torch.FloatTensor(4).uniform_(0,1)\n",
    "vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2768, 1.2498, 0.5516, 0.5476],\n",
       "        [0.3532, 1.0748, 0.8887, 0.5758],\n",
       "        [0.1202, 1.1524, 0.5168, 0.8338],\n",
       "        [0.5862, 1.5507, 0.3568, 0.9514]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector and matrix addition\n",
    "mat1 + vec1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It is not possible evaluate the \n",
    "\n",
    "    mat1 + mat2\n",
    "\n",
    "because the matrices have different dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It is not possible evaluate\n",
    "    \n",
    "    mat1 * mat2\n",
    "\n",
    "because (4,4) * (5,4)\n",
    "\n",
    "This (L1,C1) * (L2,C2) is only possible when L1=C2 and L2=C1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "Knowledge of statistical distributions is essential for weight normalization,\n",
    "weight initialization, and computation of gradients in neural networkâ€“\n",
    "based operations using PyTorch. How do we know which distributions to\n",
    "use and when to use them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli\n",
    "\n",
    "It is a discrete probability\n",
    "distribution of a random variable, which takes a value of 1 when there is\n",
    "probability that an event is a success, and takes a value of 0 when there is\n",
    "probability that an event is a failure. A perfect example of this is tossing a\n",
    "coin, where 1 is heads and 0 is tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.bernoulli import Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = Bernoulli(torch.tensor([0.3,0.6,0.9]))\n",
    "dist.sample() #saple is binary it takes 1 with p and 0 with 1-p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beta Distribution\n",
    "\n",
    "The beta distribution is a family of continuous random variables\n",
    "defined in the range of 0 and 1. \n",
    "\n",
    "This distribution is typically used for\n",
    "Bayesian inference analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.beta import Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0140])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = Beta(torch.tensor([0.5]), torch.tensor([0.5]))\n",
    "dist.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Distribution\n",
    "\n",
    "The binomial distribution is applicable when the outcome is twofold\n",
    "and **the experiment is repetitive**. It belongs to the family of discrete\n",
    "probability distribution, where the probability of success is defined as\n",
    "1 and the probability of failure is 0. The binomial distribution is used **to\n",
    "model the number of successful events over many trials.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.binomial import Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,  25.,  75., 100.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = Binomial(100, torch.tensor([0 , .2, .8, 1]))\n",
    "dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9503])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Distribution\n",
    "\n",
    "In probability and statistics, a categorical distribution can be defined\n",
    "as a generalized Bernoulli distribution, which is a discrete probability\n",
    "distribution **that explains the possible results of any random variable that\n",
    "may take on one of the possible categories, with the probability of each\n",
    "category exclusively specified in the tensor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical(probs: torch.Size([5]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 0.20, 0.20, 0.20, 0.20,0.20 event probabilities\n",
    "dist = Categorical(torch.tensor([ 0.20, 0.20, 0.20, 0.20, 0.20 ]))\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Distributions\n",
    "\n",
    "A Laplacian distribution is used in **speech recognition systems** to\n",
    "understand prior probabilities. It is also useful in **Bayesian regression** for\n",
    "deciding prior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.laplace import Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Laplace(loc: tensor([10.]), scale: tensor([0.9900]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = Laplace(torch.tensor([10.0]),torch.tensor([0.990]) )\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.1688])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Distribution\n",
    "\n",
    "A normal distribution is very useful because of the property of central\n",
    "limit theorem. It is defined by mean and standard deviations. \n",
    "\n",
    "If we know\n",
    "the mean and standard deviation of the distribution, we can estimate the\n",
    "event probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: tensor([100.]), scale: tensor([10.]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = Normal(torch.tensor([100.0]),torch.tensor([10.0]) )\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([91.5638])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
